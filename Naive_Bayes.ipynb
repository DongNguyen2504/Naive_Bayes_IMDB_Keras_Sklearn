{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycqz70-R7qyg"
      },
      "source": [
        "**Naive Bayes - IMDB movie reviews - Keras ad Sklearn**\n",
        "\n",
        "Trong bài này chúng ta sẽ dùng thuật toán phân loại Naive Bayes cho bộ dữ liệu IMDB reviews sử dụng thư viện Keras và Sklearn.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLNNwQTm9NyA"
      },
      "source": [
        "**1. Chuẩn bị dữ liệu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN0H_mxSXWov"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.datasets.imdb  import get_word_index\n",
        "from keras.preprocessing import sequence\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qExfVmXC9U5h"
      },
      "source": [
        "**1.1. Tải dữ liệu IMDB movie reviews**\n",
        "\n",
        "IMDB movie reviews là bộ dữ liệu chứa các review cho phim được phân làm 2 lớp: tiêu cực và tích cực. Dữ liệu được chia thành 2 tập: 25000 reviews cho việc huấn luyện và 25000 reviews cho việc kiểm tra. Mỗi tập sẽ chứa số reviews tiêu cực và tích cực bằng nhau.\n",
        "\n",
        "X_train bên dưới sẽ là một ma trận, trong đó mỗi dòng của ma trận là một chuỗi tương ứng với 1 review phim. Ở đây mỗi reivew đã được tiền xử lý thành một chuỗi số tự nhiên, trong đó mỗi số tự nhiên đại diện cho một từ trong từ điển. \n",
        "\n",
        "y_train là một véc tơ nhãn gồm các con số 0 (tiêu cực) và 1 (tích cực). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1c3k9FfsQeR",
        "outputId": "02ca77cc-e5e5-4a65-ac38-167a51f4bded"
      },
      "source": [
        "top_words = 10000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x46xULjFIPI8"
      },
      "source": [
        "Ở đây biến top_words hạn chế các từ của review chứa trong 10000 từ ngữ thông dụng. Bộ dữ liệu đầy đủ chứa review bao gồm các từ trong khoảng 90000 từ ngữ thông dụng. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5SK9hSJ_s1d"
      },
      "source": [
        "**1.2. Xem xét dữ liệu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owm1Bodo_jTf",
        "outputId": "359d91f5-f468-4f57-ca4c-eab30f09aafb"
      },
      "source": [
        "print('X_train_shape:', X_train.shape)\n",
        "print('y_train_shape:', y_train.shape)\n",
        "print('X_test_shape:', X_test.shape)\n",
        "print('y_test_shape:', y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_shape: (25000,)\n",
            "y_train_shape: (25000,)\n",
            "X_test_shape: (25000,)\n",
            "y_test_shape: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPajzTWkJdNw"
      },
      "source": [
        "Chúng ta sẽ download bộ từ điển từ ngữ thông dụng và chứa trong biến word_indices. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-SR5Cugu0-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a56506-59d8-46fa-c864-8b91201a3b75"
      },
      "source": [
        "word_indices = get_word_index(path=\"imdb_word_index.json\")\n",
        "len(word_indices)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88584"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbPYioLJYfc3"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_indices.items()])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aEnKWR6LNP_"
      },
      "source": [
        "Một review phim sẽ có dạng như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0Xf5VgIxnxZ",
        "outputId": "57eae3aa-8c29-49a0-ddb6-f371bf4f605b"
      },
      "source": [
        "print(X_train[0])\n",
        "print(len(X_train[0]))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3TydMg0LXcf"
      },
      "source": [
        "Chúng ta sẽ giải mã review phim vừa rồi để xem xét các từ ngữ trong review phim đó."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zEAq4V0YrRH"
      },
      "source": [
        "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in X_train[0]])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "59PGofw6YxsZ",
        "outputId": "c95b1a2b-ef1a-4079-c5cd-c448ff388e1a"
      },
      "source": [
        "decoded_review"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFPt7UgPNaHW"
      },
      "source": [
        "Dấu hỏi (?) ở đoạn review trên tương ứng với một từ không nằm trong 10000 từ thông dụng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlroNDnJfDwm"
      },
      "source": [
        "**Chuẩn bị dữ liệu**\n",
        "\n",
        "Chúng ta không thể dụng một chuỗi số tự nhiên trong thuật toán phân lớp Naive Bayes, chính vì thế chúng ta cần biến đổi dữ liệu về định dạng cần thiết.\n",
        "\n",
        "Chúng ta sẽ One-hot-encode chuỗi số tự nhiên và biến những chuỗi này thành những vec tơ những con số 0 và 1. Việc này tương ứng với việc biến một chuỗi review thành một véc tơ với độ dài bằng độ dài của top_words, là 10000. Sô 1 ở vị trí i tương ứng với từ i xuất hiện trong review, số 0 tương ứng với từ i không xuất hiện trong review. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh35fJutfHkG"
      },
      "source": [
        "def vectorize_sequences(sequences, dimension= top_words):\n",
        "    results = np.zeros((len(sequences), dimension))    # Creates an all zero matrix of shape (len(sequences),10000)\n",
        "    for i,sequence in enumerate(sequences):\n",
        "        results[i,sequence] = 1                        # Sets specific indices of results[i] to 1s\n",
        "    return results"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5izUClufdYy"
      },
      "source": [
        "# Vectorize training Data\n",
        "X_train = vectorize_sequences(X_train)\n",
        "\n",
        "# Vectorize testing Data\n",
        "X_test = vectorize_sequences(X_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUV7xZs_NOK8"
      },
      "source": [
        "Ta cũng biến đổi tập nhãn về định dạng số thực."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnQN3Tfrl8r6"
      },
      "source": [
        "y_train = np.asarray(y_train).astype('float32')\n",
        "y_test  = np.asarray(y_test).astype('float32')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0RoSUlTNqKR"
      },
      "source": [
        "Hãy xem một dữ liệu trong tập huấn luyện như thế nào."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDy8hrub2N3s",
        "outputId": "680e8dc8-361a-427c-bd2d-bc0d1708400e"
      },
      "source": [
        "X_train[0,0:150]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNQkXMtnN5mb"
      },
      "source": [
        "Chúng ta hãy coi trong chuỗi X_train[0] có bao nhiều từ xuất hiện. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skCHgFLd0w9r",
        "outputId": "d39ea1c9-ef0f-49f9-85ab-9980bcd22995"
      },
      "source": [
        "sum(X_train[0,0:10000])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr83UbiGPBj-"
      },
      "source": [
        "Các bạn có thể giải thích tại sao chiều dài của X_train[0] ban đầu là 285 mà sau khi xử lý thì chỉ còn 120 từ không?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9MPE715PJRO"
      },
      "source": [
        "**2. Xây dựng mô hình huấn luyện Naive Bayes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p-YAne9PWYG"
      },
      "source": [
        "Chúng ta sẽ xem xét thuật toán phân lớp Naive Bayes với ba loại phân phối khác nhau: Gaussian Naive Bayes, Multinomial Naive Bayes và Bernoulli Naive Bayes. Chi tiết về 3 loại phân phối này có thể xem [ở đây](https://machinelearningcoban.com/2017/08/08/nbc/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7om_hCvjQBuW"
      },
      "source": [
        "**2.1 Phân phối Gaussian Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8dDNa_e3ZVu"
      },
      "source": [
        "model = GaussianNB()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdup2Stp4lu3",
        "outputId": "2dc20993-9a37-49a1-c971-80d6e57dfed7"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRqWkkM1QTJQ"
      },
      "source": [
        "Chúng ta đã sẵng sàng để dự doán trên tập X_test và in ra độ chính xác."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYZIKy1M5OsS"
      },
      "source": [
        "y_pred = model.predict(X_test)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIXsiOfW5ZoE",
        "outputId": "9e7aae18-53f2-4407-a9cc-4c02173ad00c"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.69644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bajEHcjyQxWy"
      },
      "source": [
        "**2.2. Phân phối Multinomial Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwu4h8kB5-_Z"
      },
      "source": [
        "model = MultinomialNB()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQAIkPsX6Ufo",
        "outputId": "cac545e8-3d22-4a67-8e44-a0d71b4789c6"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ht_IbL56Whb"
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTmRnhN_6ZGf",
        "outputId": "5f163236-ec6a-4fc4-ce5d-b9e1ec526112"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.83936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT-Cl0VkREOL"
      },
      "source": [
        "**2.3. Phân phối Bernoulli Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jbr4Cpb66ftj"
      },
      "source": [
        "model = BernoulliNB()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5RJPYOx6nwk",
        "outputId": "b8532f9c-4def-4da9-81e0-3a3fa435d51d"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSak23Ll6pMl"
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGSAd5Ca6tgm",
        "outputId": "8531de9e-6d28-4e00-8c7d-ab0ee9d16eae"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.84044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc2y6A7tRLwP"
      },
      "source": [
        "Bạn có nhận xét gì về 3 độ chính xác trên? Các bạn có thể thử huấn luyện bộ dữ liệu trên dùng thuật toán Logistic regression và xem xét kết quá."
      ]
    }
  ]
}